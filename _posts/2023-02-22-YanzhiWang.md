---
layout: post
title: Exclusive Interview with Yanzhi Wang, Associate Professor of Northeastern University and CoCoPIE CEO
subtitle: Can Neuromorphic Networks Create Tomorrow's ChatGPT?
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/avatar-icon.jpeg
share-img: /assets/img/path.jpg
tags: [science, artificial intelligence, biology]
---

* Profile

Yanzhi Wang: Associate Professor in the Department of Electronics and Computer Engineering at Northeastern University, a renowned scholar
in artificial intelligence. He graduated with a Ph.D. from the University of Southern California in 2014, received the IEEE Technical
Committee's Early Career Award, as well as the Best Paper Awards at top conferences such as CLOUD, ICASSP, and ISLPED. Since 2018,
his publications in the field of artificial intelligence have gained more than 13,000 citations.

CEO of CoCoPIE, CoCoPIE is an AI startup established in 2020 with the goal of realizing real-time AI applications on chips, 
securing tens of millions in Series A funding from Primordial Capital and others. Its clients include Tencent and the renowned 
American software outsourcing service provider Cognizant.

* Question A: Can you briefly introduce your research field to those outside the industry in one sentence?

Yanzhi Wang: My main research areas focus on two aspects: firstly, implementing computation-intensive deep learning on various lightweight
devices at the edge, such as personal computers and mobile phones, enabling machine learning and speech processing capabilities on mobile
devices to make AI services ubiquitous and accessible to the public. S

econdly, neuromorphic networks involve seeking inspiration from biology
and neuroscience in the process of designing network models for machine learning, exploring whether the operational modes of the human brain
can be referenced in artificial intelligence.

* Question B: Next, we will focus on your second research direction, namely neuromorphic networks. Could you give us a general introduction
to this field?

Yanzhi Wang: Neuromorphic networks, as the name suggests, are networks that mimic neural architectures. People use hardware to construct
neuromorphic networks into configurations such as crossbar arrays, which theoretically can achieve very high energy efficiency. The main
efforts are from two perspectives: one is new hardware and new materials, which is also the main angle of our work. In this area, we are
currently focusing on superconducting materials, with one important new technology called AQFP (Adiabatic Quantum-Flux-Parametron), which
theoretically can achieve near-zero power consumption. Its energy efficiency could be ten to the fifth to ten to the sixth times higher than
existing technologies. Therefore, in such cases, it could even reach an energy efficiency ratio higher than the quantum limit.

However, this technology also has its limitations. In our previous research, we developed an automated design platform tool that can
implement any type of neural network or related application on this platform. Currently, we have implemented many types of neural networks
that can be extended to servers or GPUs, achieving extremely high accuracy while increasing the energy efficiency ratio to the order of 10^7.
In other words, if future data centers were to run on our devices instead of existing GPUs, they would consume almost no energy.
This represents my first research direction, which focuses on new hardware and materials.

My other direction is on neuromorphic networks, among which the more classic example is the spiking neural network. Unlike conventional
networks that transmit numerical values, this type of network transmits pulses. This aspect is inspired by biological patterns in the human
brain, leading many to believe that such models are more capable of simulating brain mechanisms. However, currently, neuromorphic networks
have some shortcomings in terms of accuracy, despite achieving numerous results.

Q: Can it be understood that we use some perspectives from biology to provide references for the design of AI models? Can the human brain
really be accurately modeled?

Yanzhi Wang: Yes, indeed, they can provide references. However, the human brain is very complex, and we can only make reasonable mathematical
abstractions of one or two mechanisms of the brain from certain perspectives. For example, the current multilayer neural networks are
essentially inspired by neuroscience, but the mechanism of gradient backpropagation in machine learning cannot find a corresponding mechanism
in neuroscience. If we aim not to abstract but to fully model the human brain, the result would be extremely complex, involving aspects such
as potassium and sodium ion concentrations, the polarity of ions, and the reversal of their charges. Once an AI model reaches this stage, it
becomes unnecessary; thus, neuromorphic networks are essentially an appropriate inspiration.

In spiking neural networks (SNNs), what is transmitted between neurons is not numerical values but pulses encoded based on
timing. If the spiking is denser, it indicates that the network segment is more active. Conversely, if a network segment remains idle over
a period, it gradually becomes less active. This simple property is the starting point of spiking neural networks. Fully modeling the human
brain is fundamentally unachievable; we cannot even fully model a single neuron. Therefore, when drawing from biology, it's crucial to
distinguish between what are essential mechanisms and what are limitations of biological structures (after all, the human brain does not
require electricity to function). This distinction necessitates further exploration by researchers.

* Question C: In machine learning, the mechanism of gradient backpropagation you mentioned earlier has no corresponding mechanism in the
human brain. Are there any other related mechanisms in the human brain?

Yanzhi Wang: The mechanisms in the human brain are similar to STDP (Spike-Timing-Dependent Plasticity) Learning. Simply put, the concept
of weight does exist in the human brain, where a larger parameter amplifies the input stimulus, and a negative parameter acts as an
inhibitory signal. However, the process of training these parameters is not through gradient backpropagation; at least, current neuroscience
has not proven the existence of such backpropagation mechanisms in the brain. After all, this mechanism was created to facilitate derivation.
The primary mechanism in the brain is that continuous positive feedback can increase the weight, while negative feedback reduces it.
This represents a positive learning mechanism.

In machine learning, however, forward-propagation networks do not perform as well in terms of accuracy and training efficiency compared to
those using backpropagation. Consequently, scientists have had to make compromises. In neuromorphic networks, impulses are used for operation,
but training still relies on backpropagation. This is a point of criticism in the current neuromorphic networks.

* Question D: We often hear grand narratives like "general intelligence." How far do you think current technology is from this ultimate goal?
Are there any fundamental differences in the underlying logic between human thinking and AI thinking?

Yanzhi Wang: I don't think we're that far off; recent developments like ChatGPT have convincingly demonstrated that "general intelligence"
is possible. The Transformer architecture, which is based on the attention mechanism, has unified the treatment of image, voice, and text
inputs. For images, we have Vision Transformer (ViT), and for text, GPT fundamentally uses the Transformer structure. Functionally, it has
already come close to resembling the human brain to a certain extent. During the era of ResNet and AlexNet, it was believed that the human
brain's storage capacity and the number of neurons significantly surpassed these neural networks. Although the computation speed might be
slower, we could argue that the capabilities demonstrated by ResNet and AlexNet were akin to those of a mouse, several orders of magnitude
below that of the human brain.

Now that we have tools like ChatGPT, if we can combine them with some discoveries in neuroscience, I believe it is possible to achieve an
intelligence similar to the human brain. However, it is not clear how much self-learning capability such a system would have or whether it
could also perform well on small datasets. But its storage capacity should not be much less than that of the human brain. The key is how to
achieve brain-level intelligence with a limited number of neurons (relative to the human brain) and limited training without causing
overfitting. I think this is crucial for integrating neuroscience to achieve general intelligence.
